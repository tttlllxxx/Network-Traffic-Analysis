
本研究的主要目标是提出一个新颖且广泛的物联网攻击数据集，以促进实际物联网运营中安全分析应用程序的开发。为此，在由 105 个设备组成的物联网拓扑中执行了 33 次攻击。

这些攻击分为七类，分别是 DDoS、DoS、Recon、基于 Web、暴力破解、欺骗和 Mirai。最后，所有攻击都是由恶意 IoT 设备针对其他 IoT 设备执行的。

## 数据集目录
***


主数据集目录（CICIoT2023）包含四个与不同文件相关的子目录，分别是：

1. **PCAP：包含攻击期间捕获的原始流量（`.pcp` 文件）；

2. **CSV：包含从原始文件中提取的特征，用于机器学习（`ML`）评估（`.csv` 文件）；

3. **example：一个 `jupyter` 笔记本，展示如何使用数据集来训练和评估攻击检测和分类中的机器学习 (ML) 模型；

4. **补充材料：在收集和整理攻击数据的过程中使用的工具的源代码和说明。我们使用 Mergecap 合并多个 `.pcap` 文件，使用 `PySpark` 处理数据，使用 `TCPDump` 将 `.pcap` 文件拆分为多个较小的文件，并使用 `DPKT` 提取特征。

## Example
***

### 导入库及文件
```Python
import pandas as pd
import numpy as np
import os
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')  #忽略所有警告信息
from sklearn.linear_model import LogisticRegression
from sklearn.impute import SimpleImputer
```

- `pandas`: 用于数据处理，特别是数据表格（DataFrame）操作。
- `numpy`: 提供高效的数组运算，常用于数值计算和矩阵操作。
- `os`: 处理文件路径、目录操作等，与操作系统交互。
- `tqdm`: 用于显示进度条，适用于遍历大型数据集时提升可视化体验。
- `warnings`: 该模块用于管理Python的警告信息。
- `LogisticRegression`: 从 `sklearn.linear_model` 导入逻辑回归模型，用于分类任务（如二分类或多分类问题）。
- `SimpleImputer`: 从 `sklearn.impute` 导入 `SimpleImputer`，用于处理缺失值（例如用均值、中位数或众数填充缺失值）。
  
>[!note] 逻辑回归模型
>逻辑回归（Logistic Regression）是一种用于**分类任务**的机器学习算法，通常用于**二分类问题**，但也可以扩展到多分类问题。（不支持GPU加速）
>**核心思想：
>- 使用 **线性回归** 的思想计算输入变量的加权和（`w*x + b`）。
>- 然后使用 **Sigmoid** 函数（S形函数）将输出映射到 `[0,1]` 之间，表示某个类别的概率。
>Sigmoid 函数公式：
>$$
σ(z)= \frac{1}{1+e^{-z}}$$

```Python
DATASET_DIRECTORY = '../CICIoT2023/'  #..代表上一级目录。
```

定义了一个变量 `DATASET_DIRECTORY`，它存储了数据集的目录路径 `'../CICIoT2023/'`。
路径指向的是**当前代码所在目录的上一级目录中的 `CICIoT2023` 文件夹**。

### 划分数据集

```Python
df_sets = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('.csv')]
df_sets.sort()  #按照文件名进行排序
training_sets = df_sets[:int(len(df_sets)*.8)]  #从索引0到int(len(df_sets)*.8的部分
test_sets = df_sets[int(len(df_sets)*.8):]  #从int(len(df_sets)*.8到最后
```

从指定目录中获取 .csv 文件，并按 80% 训练集、20% 测试集的比例进行划分。

- `os.listdir(DATASET_DIRECTORY)`:  
    获取 `DATASET_DIRECTORY` 目录下的所有文件和文件夹的列表。
- `if k.endswith('.csv')`:  
    过滤出所有以 `.csv` 结尾的文件，即数据集文件。
- `df_sets` 是一个 `.csv` 文件名的列表。

- `len(df_sets) * 0.8` 计算出 80% 的索引位置，并转换为整数（`int()`）。
- `training_sets` 取前 80% 作为训练集。
- `test_sets` 取剩下的 20% 作为测试集。
  
### 定义特征列

```Python
X_columns = [
    'Header_Length', 'Protocol Type', 'Rate', 'fin_flag_number', 'syn_flag_number', 'rst_flag_number', 
    'psh_flag_number', 'ack_flag_number', 'ece_flag_number', 'cwr_flag_number', 'ack_count', 'syn_count', 
    'fin_count', 'rst_count', 'HTTP', 'HTTPS', 'DNS', 'Telnet', 'SMTP', 'SSH', 'IRC', 'TCP', 'UDP', 
    'DHCP', 'ARP', 'ICMP', 'IPv', 'LLC', 'Tot sum', 'Min', 'Max', 'AVG', 'Std', 'Tot size', 'IAT', 
    'Number', 'Variance'
]
y_column = 'Label'
```

**`X_columns`**：特征列

**`y_column`**：目标列
`Label` 一般是一个**二分类（0 或 1）**，用于区分正常流量（0）和攻击流量（1）。

>[!note] 网络流量特征
> **🔹基本网络特征**
>- **`Header_Length`**：数据包的头部长度。
>- **`Protocol Type`**：协议类型（TCP、UDP、ICMP等）。
>- **`Rate`**：某段时间内的流量速率。
>
 >**🔹 TCP/IP 标志位**
>- **`fin_flag_number`、`syn_flag_number`、`rst_flag_number`、`psh_flag_number`、`ack_flag_number`**：TCP 标志位（如 SYN、ACK、FIN、RST等），用于检测攻击模式（如SYN Flood、RST攻击等）。
>- **`ack_count`、`syn_count`、`fin_count`、`rst_count`**：记录 ACK、SYN、FIN、RST 包的数量。
>
>**🔹 应用层协议**
>- **`HTTP`、`HTTPS`、`DNS`、`Telnet`、`SMTP`、`SSH`、`IRC`**：是否属于这些协议。
>- **`TCP`、`UDP`、`DHCP`、`ARP`、`ICMP`、`IPv`、`LLC`**：是否使用这些协议。
>
>**🔹 统计特征**
>- **`Tot sum`**：总数据量。
>- **`Min`、`Max`、`AVG`、`Std`**：统计学特征，如最小值、最大值、均值、标准差。
>- **`Variance`**：方差，衡量数据的波动性。
>- **`IAT`**（Inter-Arrival Time）：数据包之间的到达时间间隔。

### 创建标准化对象

```Python
from sklearn.preprocessing import MinMaxScaler, StandardScaler
scaler = StandardScaler()
```

- **`MinMaxScaler`** 和 **`StandardScaler`** 都是 `sklearn.preprocessing` 中的**数据归一化/标准化工具**。
- `scaler = StandardScaler()` 创建了一个**标准化对象**，用于对数据进行标准化转换。
  
#### `StandardScaler`

**`StandardScaler`** 采用**Z-Score 标准化**，将数据转换为**均值为 0，标准差为 1** 的分布：
$$
X′= \frac{X - \mu}{\sigma}
$$

- $μ$ 是特征的均值。
- $σ$ 是特征的标准差。
  
**作用：**
- 消除量纲影响，让不同特征的数值在相同尺度上。
- 加快梯度下降，有助于提高机器学习模型的收敛速度。
- 适用于正态分布数据（若数据服从高斯分布，标准化效果更好）。

**用法：**
```Python
from sklearn.preprocessing import StandardScaler
import numpy as np

# 创建数据
X = np.array([[10, 1000], [20, 2000], [30, 3000]])

# 初始化 StandardScaler
scaler = StandardScaler()

# 进行标准化
X_scaled = scaler.fit_transform(X)

print(X_scaled)

```

```Out
[[-1.22474487 -1.22474487]
 [ 0.          0.        ]
 [ 1.22474487  1.22474487]]
```

- `-1.22474487` 表示这个值比均值小 1.22 个标准差。
- `1.22474487` 表示这个值比均值大 1.22 个标准差。
  
#### `MinMaxScaler`

计算方式是：
$$
X^′= \frac{X - X_{\min}}{X_{\max} - X_{\min}}​​
$$
- 结果会被缩放到 **[0,1] 或 [-1,1]** 之间。
- 适用于**非正态分布**数据，比如图像像素（0-255）。

### 定义模型

```Python
ML_models = [
        LogisticRegression(n_jobs=-1),
]

ML_names = [
        "LogisticRegression",
]
```
- **`ML_models`**：存储了一个机器学习模型（**逻辑回归**）。
- **`ML_names`**：存储了模型名称，方便后续打印结果或做可视化分析。
- `n_jobs=-1`：表示**使用所有 CPU 核心进行并行计算**，加速训练（如果数据集较大，训练速度会更快）。
  
### 训练集数据预处理
  
```Python
for train_set in tqdm(training_sets):
    # 读取数据
    d = pd.read_csv(DATASET_DIRECTORY + train_set)
    # 选择特征列
    X = d[X_columns]
    Y = d[y_column]
    # 处理无穷大
    X.replace([np.inf, -np.inf], np.nan, inplace=True)
    # 处理 NaN（用均值填充）
    imputer = SimpleImputer(strategy='mean')
    X = imputer.fit_transform(X)
	# 处理标签列中的缺失值
    Y.fillna("Unknown", inplace=True)
```

使用 `pandas` 的 `read_csv()` 函数读取 `train_set` 对应的 CSV 文件。
- `DATASET_DIRECTORY + train_set` 是文件路径，`train_set` 是每个训练集的文件名。
- 读取的内容会被存储在 `d` 这个 `DataFrame` 中。
  
通过 `replace()` 将 `X` 中的无穷大 (`np.inf`) 和负无穷大 (`-np.inf`) 值替换为 `NaN`。

`SimpleImputer(strategy='mean')`：处理缺失值。`strategy='mean'` 表示将缺失值填充为每列的 **均值**。

`fit_transform(X)`：
	`fit()`：计算每列的均值。
	`transform()`：将每列的缺失值 `NaN` 用均值填充，返回一个新的 NumPy 数组（注意，这里 `X` 被转换成了 NumPy 数组）。

`fillna("Unknown", inplace=True)` 用 `"Unknown"` 字符串填充 `Y` 中的所有缺失值 `NaN`。

### 标准化数据

```Python
scaler.fit(X)
X = scaler.transform(X)
```

- [[#`StandardScaler`|scaler]] 是 `StandardScaler`标准化对象，它用来**计算特征的均值和标准差**。
- `fit(X)` 计算并存储 `X` 中每一列的均值（mean）和标准差（standard deviation）。
    - 对于每一列特征 `X_i`，`StandardScaler` 会计算： 
      $$\mu_i = \text{mean}(X_i) \quad \text{和} \quad \sigma_i = \text{std}(X_i)$$
    - 这些计算结果会被 `scaler` 保存下来，以便在 `transform(X)` 中使用。
      
 
 
- `transform(X)` 是将 `X` 中的每一列特征进行**标准化**： $$X'_i = \frac{X_i - \mu_i}{\sigma_i}$$
    - $X'_i$ 是标准化后的特征值。
    - 对每个特征 $X_i$，会减去该特征的均值 $\mu_i$，然后除以标准差 $\sigma_i$，将其转换为均值为 0、标准差为 1 的分布。
- 这样，标准化后的 `X` 中每一列的均值将接近 0，标准差接近 1。
  
### 训练模型

```Python
for model in (ML_models): 
	model.fit(X, Y) 
del d
```


[[#定义模型|ML_models]]只定义了一个模型即LogisticRegression。
**`model.fit(X, Y)`**：
- `fit()` 方法用于训练模型。
- `X` 是训练数据中的特征矩阵，`Y` 是对应的标签向量。
- 该操作将基于 `X` 和 `Y` 进行训练，学习出模型的参数。

**`del d`** 用于删除变量 `d`，以节省内存空间。

### 模型预测

```Python
y_test = []
preds = {i:[] for i in range(len(ML_models))}
for test_set in tqdm(test_sets): # 遍历每个测试集
    d_test = pd.read_csv(DATASET_DIRECTORY + test_set)
    X_test = d_test[X_columns]
    # 处理无穷大
    X_test.replace([np.inf, -np.inf], np.nan, inplace=True)
    # 处理 NaN（用均值填充）
    imputer = SimpleImputer(strategy='mean')
    X_test = imputer.fit_transform(X_test)
    X_test = scaler.transform(X_test)  # 标准化处理

    y_test += list(d_test[y_column].values)

    for i in range(len(ML_models)):
        model = ML_models[i]
        y_pred = list(model.predict(X_test))
        preds[i] = preds[i] + y_pred
```

- **`y_test = []`**：这是一个空列表，用于存储所有测试集的真实标签。
- **`preds = {i:[] for i in range(len(ML_models))}`**：创建一个字典 `preds`，它的键是模型的索引，值是一个空列表，用于存储每个模型的预测结果。
  
  通过 `for` 循环遍历每个模型，调用 `model.predict(X_test)` 对测试集进行预测。
- `model.predict(X_test)` 返回的是模型对 `X_test` 的预测结果。
- 预测结果 `y_pred` 被转换为列表，并加入到 `preds` 字典中，`preds[i]` 是模型 `i` 的预测结果。
  
### 输出结果

```Python
from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score
for k,v in preds.items():
    y_pred = v
    print(f"##### {ML_names[k]} (34 classes) #####")
    print('accuracy_score = ', accuracy_score(y_pred, y_test))
    print('recall_score = ', recall_score(y_pred, y_test, average='macro'))
    print('precision_score = ', precision_score(y_pred, y_test, average='macro'))
    print('f1_score = ', f1_score(y_pred, y_test, average='macro'))
    print()
    print()
    print()
```

- `accuracy_score`：计算分类模型的**准确率**，即正确预测的样本占总样本的比例。
- `recall_score`：计算分类模型的**召回率**，即正确预测的正类占所有正类的比例。
- `precision_score`：计算分类模型的**精确率**，即正确预测的正类占所有预测为正类的比例。
- `f1_score`：计算**F1分数**，是精确率和召回率的调和平均数，衡量分类模型的综合性能。
  
  - **`for k, v in preds.items():`**：
    - `preds` 是一个字典，其中每个键 `k` 对应一个模型（例如：`LogisticRegression`），每个值 `v` 是该模型的预测结果列表。
    - `k` 是模型的索引，`v` 是该模型的预测结果。
- **`y_pred = v`**：
    - `y_pred` 是当前模型 `k` 的预测结果。

```Out
##### LogisticRegression (34 classes) ##### 
accuracy_score: 0.7518522629130883 
recall_score: 0.5493143330727824 
precision_score: 0.465848001355893 
f1_score: 0.466456453946256



```

>[!note] `average='macro'`
>`average='macro'` 表示对每个类别单独计算评估指标（如召回率、精确率、F1分数），然后对所有类别的评估结果进行**不加权平均**。
>**宏观平均**（Macro-average）意味着每个类的贡献是相等的，不管各类样本的数量有多少

### 攻击映射

#### 7类

```Python
dict_7classes = {}
dict_7classes['DDOS-RSTFINFLOOD'] = 'DDOS'
dict_7classes['DDOS-PSHACK_FLOOD'] = 'DDOS'
dict_7classes['DDOS-SYN_FLOOD'] = 'DDOS'
dict_7classes['DDOS-UDP_FLOOD'] = 'DDOS'
dict_7classes['DDOS-TCP_FLOOD'] = 'DDOS'
dict_7classes['DDOS-ICMP_FLOOD'] = 'DDOS'
dict_7classes['DDOS-SYNONYMOUSIP_FLOOD'] = 'DDOS'
dict_7classes['DDOS-ACK_FRAGMENTATION'] = 'DDOS'
dict_7classes['DDOS-UDP_FRAGMENTATION'] = 'DDOS'
dict_7classes['DDOS-ICMP_FRAGMENTATION'] = 'DDOS'
dict_7classes['DDOS-SLOWLORIS'] = 'DDOS'
dict_7classes['DDOS-HTTP_FLOOD'] = 'DDOS'

dict_7classes['DOS-UDP_FLOOD'] = 'DOS'
dict_7classes['DOS-SYN_FLOOD'] = 'DOS'
dict_7classes['DOS-TCP_FLOOD'] = 'DOS'
dict_7classes['DOS-HTTP_FLOOD'] = 'DOS'

dict_7classes['MIRAI-GREETH_FLOOD'] = 'MIRAI'
dict_7classes['MIRAI-GREIP_FLOOD'] = 'MIRAI'
dict_7classes['MIRAI-UDPPLAIN'] = 'MIRAI'

dict_7classes['RECON-PINGSWEEP'] = 'RECON'
dict_7classes['RECON-OSSCAN'] = 'RECON'
dict_7classes['RECON-PORTSCAN'] = 'RECON'
dict_7classes['VULNERABILITYSCAN'] = 'RECON'
dict_7classes['RECON-HOSTDISCOVERY'] = 'RECON'

dict_7classes['DNS_SPOOFING'] = 'SPOOFING'
dict_7classes['MITM-ARPSPOOFING'] = 'SPOOFING'

dict_7classes['BENIGN'] = 'BENIGN'
dict_7classes['UNKNOWN'] = 'BENIGN'

dict_7classes['BROWSERHIJACKING'] = 'WEB'
dict_7classes['BACKDOOR_MALWARE'] = 'WEB'
dict_7classes['XSS'] = 'WEB'
dict_7classes['UPLOADING_ATTACK'] = 'WEB'
dict_7classes['SQLINJECTION'] = 'WEB'
dict_7classes['COMMANDINJECTION'] = 'WEB'

dict_7classes['DICTIONARYBRUTEFORCE'] = 'BRUTEFORCE'
```

字典 `dict_7classes`，用于将不同的攻击类型映射到七个类别中的一个。

>[!note] 网络攻击
>- **DDOS (分布式拒绝服务攻击)**：
>	- 例如：`DDOS-RSTFINFLOOD`、`DDOS-PSHACK_FLOOD` 等。
>- **DOS (拒绝服务攻击)**：
>	- 例如：`DOS-UDP_FLOOD`、`DOS-SYN_FLOOD` 等。
>- **MIRAI (Mirai 恶意软件攻击)**：
>	- 例如：`MIRAI-GREETH_FLOOD`、`MIRAI-GREIP_FLOOD` 等。
>- **RECON (侦察攻击)**：
> 	- 例如：`RECON-PINGSWEEP`、`RECON-OSSCAN` 等。
>- **SPOOFING (欺骗攻击)**：
> 	- 例如：`DNS_SPOOFING`、`MITM-ARPSPOOFING`。
>- **BENIGN (正常流量)**：
> 	- 例如：`BENIGN` 和 `UNKNOWN`。
>- **WEB (Web攻击)**：
 >	- 例如：`BROWSERHIJACKING`、`BACKDOOR_MALWARE` 等。
>- **BRUTEFORCE (暴力破解攻击)**：
> 	- 例如：`DICTIONARYBRUTEFORCE`。
   
#### 2类

```Python
dict_2classes = {}
dict_2classes['DDOS-RSTFINFLOOD'] = 'ATTACK'
dict_2classes['DDOS-PSHACK_FLOOD'] = 'ATTACK'
dict_2classes['DDOS-SYN_FLOOD'] = 'ATTACK'
dict_2classes['DDOS-UDP_FLOOD'] = 'ATTACK'
dict_2classes['DDOS-TCP_FLOOD'] = 'ATTACK'
dict_2classes['DDOS-ICMP_FLOOD'] = 'ATTACK'

dict_2classes['DDOS-SYNONYMOUSIP_FLOOD'] = 'ATTACK'
dict_2classes['DDOS-ACK_FRAGMENTATION'] = 'ATTACK'
dict_2classes['DDOS-UDP_FRAGMENTATION'] = 'ATTACK'
dict_2classes['DDOS-ICMP_FRAGMENTATION'] = 'ATTACK'
dict_2classes['DDOS-SLOWLORIS'] = 'ATTACK'
dict_2classes['DDOS-HTTP_FLOOD'] = 'ATTACK'

dict_2classes['DOS-UDP_FLOOD'] = 'ATTACK'
dict_2classes['DOS-SYN_FLOOD'] = 'ATTACK'
dict_2classes['DOS-TCP_FLOOD'] = 'ATTACK'
dict_2classes['DOS-HTTP_FLOOD'] = 'ATTACK'

dict_2classes['MIRAI-GREETH_FLOOD'] = 'ATTACK'
dict_2classes['MIRAI-GREIP_FLOOD'] = 'ATTACK'
dict_2classes['MIRAI-UDPPLAIN'] = 'ATTACK'

dict_2classes['RECON-PINGSWEEP'] = 'ATTACK'
dict_2classes['RECON-OSSCAN'] = 'ATTACK'
dict_2classes['RECON-PORTSCAN'] = 'ATTACK'
dict_2classes['VULNERABILITYSCAN'] = 'ATTACK'
dict_2classes['RECON-HOSTDISCOVERY'] = 'ATTACK'

dict_2classes['DNS_SPOOFING'] = 'ATTACK'
dict_2classes['MITM-ARPSPOOFING'] = 'ATTACK'

dict_2classes['BENIGN'] = 'BENIGN'
dict_2classes['UNKNOWN'] = 'BENIGN'

dict_2classes['BROWSERHIJACKING'] = 'ATTACK'
dict_2classes['BACKDOOR_MALWARE'] = 'ATTACK'
dict_2classes['XSS'] = 'ATTACK'
dict_2classes['UPLOADING_ATTACK'] = 'ATTACK'
dict_2classes['SQLINJECTION'] = 'ATTACK'
dict_2classes['COMMANDINJECTION'] = 'ATTACK'

dict_2classes['DICTIONARYBRUTEFORCE'] = 'ATTACK'
```

字典 `dict_2classes`，将不同的攻击类型映射到：`ATTACK` 或 `BENIGN`（正常流量）。

### 字典映射

```Python
d[y_column] = [dict_7classes[k] for k in d[y_column]]
```

```Python
d[y_column] = [dict_2classes[k] for k in d[y_column]]
```

**`[dict_7classes[k] for k in d[y_column]]`**：

- 这是一个列表推导式，用来遍历 `d[y_column]` 中的每个元素（也就是每个标签），通过 `dict_7classes[k]` 从字典中查找并获取对应的简化标签。
- `k` 是 `d[y_column]` 中的每个原始标签（比如 `DDOS-RSTFINFLOOD`）。
- `dict_7classes[k]` 根据 `k` 查找 `dict_7classes` 字典中的值，得到简化后的类别标签（如 `DDOS`）。
  
### 映射结果

#### 7类

```Out
##### LogisticRegression_7 (8 classes) ##### 
accuracy_score = 0.8296364015363655 
recall_score = 0.6887042816911841 
precision_score = 0.5302193234524215 
f1_score = 0.5513885230861422



```

#### 2类

```Out
##### LogisticRegression (2 classes) ##### 
accuracy_score: 0.9871493187973056 
recall_score: 0.8612072363868772 
precision_score: 0.854005573046825 
f1_score: 0.8575679913187281



```