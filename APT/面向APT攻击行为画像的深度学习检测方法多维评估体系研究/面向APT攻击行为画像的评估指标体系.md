# APT攻击行为画像评估指标体系（初稿）

## 一、概述

本指标体系旨在为APT攻击行为画像的生成与检测效果提供系统性、多维度的评价标准，主要应用于不同深度学习检测方法的比较与能力评估，推动APT攻击检测的科学化与实用化。

---

## 二、APT攻击行为画像检测方法多维评估体系（评估指标表）
| 维度               | 指标名称                 | 描述说明                                                                 | 示例系统参考        | 建议评估方式                         |
|--------------------|--------------------------|--------------------------------------------------------------------------|---------------------|--------------------------------------|
| **检测准确性维度** | True Positive Rate (TPR) | 成功识别的攻击样本所占比例                                               | Pikachu, Kairos     | 混淆矩阵计算                         |
|                    | False Positive Rate (FPR)| 被误报为攻击的正常样本比例                                               | NetWalk             | 混淆矩阵计算                         |
|                    | Precision                | 检测为攻击的样本中真实攻击的比例                                         | StreamSpot          | 精确度指标（P）                      |
|                    | Recall                   | 所有真实攻击中被识别出来的比例                                           | Pikachu             | 召回率指标（R）                      |
|                    | F1-Score                 | 精确率和召回率的调和平均数                                               | Log2Vec             | F1 = 2PR/(P+R)                       |
|                    | AUC-ROC                  | 模型在不同阈值下的性能综合指标                                           | 任意分类模型        | 曲线计算工具（如scikit-learn）       |
| **检测粒度维度**   | IoC级别检测              | 是否能检测IP、域名、哈希等简单指标                                       | 基于规则方法        | 观察检测结果输出                     |
|                    | 事件级别检测             | 能否检测出某一特定行为事件（如权限提升）                                 | Unicorn             | 行为级别标注与对比                   |
|                    | 路径级别检测             | 能否输出一条完整攻击路径或因果链                                         | Kairos, ThreaTrace  | 可视化输出攻击路径                   |
|                    | 系统级状态识别           | 是否能判断某主机/系统是否处于被APT控制状态                               | Pikachu             | 全图分类或状态预测                   |
| **可解释性维度**   | 可视化输出               | 是否能生成攻击链/图结构用于人工分析                                      | Kairos, FRAPpuccino | 图输出模块或日志链输出               |
|                    | 特征权重说明             | 能否解释模型为何判定此行为为异常                                         | GNN with attention  | 输出注意力权重/SHAP/LIME             |
|                    | 事件因果路径             | 是否能指出事件发生的前因后果关系                                         | Log2Vec             | 上下文提取与路径溯源                 |
| **抗规避能力维度** | 时间扰动鲁棒性           | 模型是否能抵抗攻击者在行为中插入延迟、换顺序等扰动手法                   | Pikachu             | 插入延迟后测试性能变化               |
|                    | 冗余操作注入鲁棒性       | 是否能抵抗插入伪造正常行为后的规避                                       | ThreaTrace          | 构造冗余操作扰动样本                 |
|                    | 图结构扰动鲁棒性         | 节点、边略微扰动后模型性能是否大幅下降                                   | GraphShield 系列    | 图对抗攻击或边扰动实验               
|
| **可扩展性维度**   | 模型训练效率             | 模型训练所需时间与计算资源                                                | Kairos              | 记录训练耗时/内存GPU使用             |
|                    | 在线/流式检测能力        | 是否支持流式输入的在线处理能力                                           | StreamSpot, NetWalk | 单样本平均处理耗时（ms）             |
|                    | 系统部署难度             | 是否易于部署为服务或模块（如可与SIEM对接）                              | FRAPpuccino         | API接口、系统集成能力测试           |
| **适应性维度**     | 标签依赖程度             | 是否必须依赖大量攻击样本进行训练                                         | Supervised vs One-class | 标签数量 vs 模型性能对比         |
|                    | 跨场景泛化能力           | 模型能否适应不同组织/主机/环境下的数据分布                             | 所有系统             | 不同数据集下性能对比（如DAPT vs CERT）|
|                    | 增量学习能力             | 是否支持边检测边学习、模型自适应更新                                     | NetWalk, Unicorn    | 模拟系统更新后模型持续训练         |

---


