模型和Hugging Face自定义的一些类进行完整的封装，以契合网络上的主流模型 啊啊是对方过后就哭了；‘

加上了Linear层和SoftMax层
## 代码
```Python
class MiniMindForCasualLM(PreTrainedModel, GenerationMixin):
    config_class = MiniMindConfig

    def __init__(self, config: MiniMindConfig):
        self.config = config

        super().__init__(config)

        self.model = MinimindModel(config)

        self.lm_head = nn.Linear(
            self.config.hidden_size, self.config.vocab_size, bias=False
        )

        # 权重共享
        # 输出层的权重和嵌入层的权重共享
        self.model.embed_tokens.weight = self.lm_head.weight

        self.OUT = CausalLMOutputWithPast()

    def forward(
        self,
        input_ids: Optional[torch.Tensor] = None,
        attention_mask: Optional[torch.Tensor] = None,
        past_key_values: Optional[Tuple[Tuple[torch.Tensor]]] = None,
        use_cache: bool = False,
        Logits_to_keep: Union[int, torch.Tensor] = 0,
        **args
    ):
        hidden_states, past_key_values = self.model(
            input_ids=input_ids,
            attention_mask=attention_mask,
            past_key_values=past_key_values,
            use_cache=use_cache,
            **args,
        )
        # logits to keep 是整数，那就保留最后n个位置
        # 生成的时候只需要最后的logits来预测下一个token
        slice_indices = (
            slice(-Logits_to_keep, None)
            if isinstance(Logits_to_keep, int)
            else Logits_to_keep
        )
        logits=self.lm_head(hidden_states[:,slice_indices,:])
        
        self.OUT.__setitem__("last_hidden_state",hidden_states)
        self.OUT.__setitem__("logits",logits)
        self.OUT.__setitem__("past_key_values",past_key_values)
        
        return self.OUT
```