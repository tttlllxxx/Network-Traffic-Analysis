## RoPE 旋转位置编码
**把向量的每两个相邻维度看成一个二维平面坐标，在这个平面里按位置相关的角度做旋转**。
**在点积注意力中自然引入相对位置信息。**
相对位置编码
$$q=[q_1,q_2] \to 转m\cdot\theta \to q_m=[q_1\cdot cos(m\theta)-q_2\cdot sin(m\theta),q_1\cdot sin(m\theta)+q_2\cdot cos(m\theta)]$$
$$k=[k_1,k_2] \to 转n\cdot\theta \to k_n=[k_1\cdot cos(n\theta)-k_2\cdot sin(n\theta),k_1\cdot sin(n\theta)+k_2\cdot cos(n\theta)]$$
计算点积
$$(q_1\cdot cos(m\theta)-q_2\cdot sin(m\theta))\cdot(k_1\cdot cos(n\theta)-k_2\cdot sin(n\theta))$$
$$+$$
$$(q_1\cdot sin(m\theta)+q_2\cdot cos(m\theta))\cdot(k_1\cdot sin(n\theta)+k_2\cdot cos(n\theta))$$
展开
$$q_1\cdot k_1\cdot [cos(m\theta)cos(n\theta)+sin(m\theta)sin(n\theta)]$$
$$q_2\cdot k_2\cdot [sin(m\theta)sin(n\theta)+cos(m\theta)cos(n\theta)]$$
$$q_1\cdot k_2\cdot [sin(m\theta)cos(n\theta)-cos(m\theta)sin(n\theta)]$$
$$q_2\cdot k_1\cdot [cos(m\theta)sin(n\theta)-sin(m\theta)cos(n\theta)]$$
三角恒等变换
$$(q_1\cdot k_1+q_2\cdot k_2)\cdot cos((m-n)\theta)+(q_1\cdot k_2+q_2\cdot k_1)\cdot sin((m-n)\theta)$$
$q,k$为原始数值，故位置信息只由$cos((m-n)\theta)$以及$sin((m-n)\theta$决定 

RoPE 给每对维度 $(2i, 2i+1)$做一个二维旋转：
$$\begin{pmatrix}
q'_{2i} \\
q'_{2i+1}
\end{pmatrix}
=
\begin{pmatrix}
\cos(\theta_i) & -\sin(\theta_i) \\
\sin(\theta_i) & \cos(\theta_i)
\end{pmatrix}
\begin{pmatrix}
q_{2i} \\
q_{2i+1}
\end{pmatrix}=\begin{pmatrix}
\cos(\theta_i)\cdot q_{2i} -\sin(\theta_i)\cdot q_{2i+1}\\
\sin(\theta_i)\cdot q_{2i} +\cos(\theta_i)\cdot q_{2i+1}
\end{pmatrix}$$
## YaRN 
RoPE原始频率计算为
$$freqs_i=\frac{1}{{rope_{base}}^{(2i/\ dim)}}$$
其中 $i$ 是频率编号（$0$ 到 $\frac{dim}{2}-1$）
$freqs$ 是所有频率的列表，用来生成 RoPE 的 $cos$/$sin$ 旋转角度$\theta$
$$\theta=freqs\cdot pos$$
可见：$i$越小，$freqs$越大；$i$越大，$freqs$越小
如果模型本身的只能处理4096长度，当输入序列为5000时，就无法处理信息。
方法一：把5000压缩到4096  会损失一定信息
方法二：对高低频使用不同处理方式（如下关于scale公式所示）
	- 对于高频：复杂放缩
	- 对于低频：普通放缩

YaRN外推RoPE到更长的序列

计算哪个维度超出序列长（原始频率范围）
$$corr_{dim}=min\{ i | \frac{2\pi}{freqs\{ i\}}>original_{max}\}$$

放缩power，辅助高频低频缩放，用来在 fast/slow $\beta$ 值之间插值
$$power_i=\frac{i}{max(dim//2-1,1)}$$
插值得到每个维度自己的 $\beta$ 值
$$\beta_i=\beta_{slow}+(\beta_{fast}-\beta_{slow})\cdot power_i$$

$$
scale_i=
\begin{cases}
\frac{\beta_i\cdot f-\beta_i+1}{\beta_i\cdot f}, &\quad if\quad i<corr_{dim}(高频/短波长部分)\\
\frac{1}{f},  &\quad if\quad i\ge corr_{dim}(低频/长波长部分)
\end{cases}
$$
其中$f$为缩放因子,表示希望把序列长度扩展多少倍


## 相关torch方法
### torch.where
```Python
x=torch.tensor([1,2,3,4,5])
y=torch.tensor([10,20,30,40,50])
condition=x>3

result=torch.where(condition,x,y) # 过滤条件，x张量中不符合的会有y张量中对应位置替代

print(result) # Output:tensor[(10,20,30,4,5)]
```

### torch.arange
```Python
t1=torch.arange(0,10,2) # 0是开始，10是结束，2是步长
print(t1) # Output:tensor([0,2,4,6,8])

t2=torch.arange(5,0,-1)
print(t2) # Output:tensor([5,4,3,2,1])
```

### torch.outer
```Python
v1=torch.tensor([1,2,3])
v2=torch.tensor([4,5,6])
result=torch.outer(v1,v2)
print(result)
# Output:tensor([4,5,6],
#				[8,10,12],
#				[12,15,18])
```

### torch.cat
```Python
t1=torch.tensor([[[1,2,3],[4,5,6]],[[13,14,15],[16,17,18]]]) # torch.Size([2,2,3])
t2=torch.tensor([[[7,8,9],[10,11,12]],[[19,20,21],[22,23,24]]]) #torch.Size([2,2,3])
result=torch.cat((t1,t2),dim=0) # torch.Size([4,2,3])
result=torch.cat((t1,t2),dim=1) # torch.Size([2,4,3])
result=torch.cat((t1,t2),dim=-1) # torch.Size([2,2,6])
```

### torch.unsqueeze(dim)
```Python
# 在第dim个位置插入一个大小为1的新维度。
t1=torch.tensor([1,2,3]) # torch.Size([3])
t2=t1.unsqueeze(0)
print(t2) # tensor([[1,2,3]])
print(t2.shape) # torch.Size([1,3])
```

## 代码
```Python
def precomput_freqs_cis(
    dim:int,
    end:int=int(32*1024),
    rope_base:float=1e6,
    rope_scaling:Optional[dict]=None
):
    # 写出最初RoPE式子
    freqs=1.0/(rope_base**torch.arrange(0,dim,2)[:dim//2].float()/dim)
    
    # 从配置中读取 RoPE 扩展参数，用来把原本训练时的 RoPE 最大长度（如 2048）扩展到更长的上下文（如 8k、16k），并控制不同维度的频率扩展速度。
    if rope_scaling is not None:
        orig_max,factor,beta_fast,beta_slow=(
            rope_scaling.get("original_max_position_embeddings",2048), # 原始模型训练时的最大序列长度
            rope_scaling.get("factor",4), # 表示希望把序列长度扩展多少倍
            rope_scaling.get("beta_fast",4), # 快频率（高频）拉伸 4 倍
            rope_scaling.get("beta_slow",1), # 慢频率（低频）1 倍（基本不变）
        )    
		# 计算corr_dim
		# next(iterator, default_value) 
		# 如果 iterator 还能取到值 → 返回下一个值
		# 如果已经没有值了 → 返回 default_value（不报错）
	    corr_dim=next((i for i in range(dim//2) if 2*math.pi/freqs[i]>orig_max),dim//2)
		# 计算power
	    power=torch.arrange(0,dim//2,device=freqs.device).float()/(max(dim//2-1,1))
		# 计算beta
	    beta=beta_slow+(beta_fast-beta_slow)*power
		# 计算scale
	    scale=torch.where(
	        torch.arrange(dim//2,device=freqs.device)<corr_dim, #condition
	        (beta*factor-beta+1)/(beta*factor),
	        1.0/factor
	    )
		# 应用scale
	    freqs=freqs*scale
	
	# 生成位置索引，与频率相乘
    t=torch.arrange(end,device=freqs.device)
    freqs=torch.outer(t,freqs).float() # [end,dim//2]  pos*ω
	
	# 返回一个cos和sin
    freqs_cos=torch.cat([torch.cos(freqs),torch.cos(freqs)],dim=-1) # [end,dim]
    freqs_sin=torch.cat([torch.sin(freqs),torch.sin(freqs)],dim=-1)
    return freqs_cos,freqs_sin
    
def apply_rotary_pos_emb(q,k,cos,sin,unsqueeze_dim=1):
    # [a,b] -> [-b,a]
    def rotate_half(x):
        # x.shape[-1]取最后一个维度的中点
        # x[...,x.shape[-1]//2:]取后半部分
        # x[...,:x.shape[-1]//2]取前半部分
        return torch.cat([-x[...,x.shape[-1]//2:],x[...,:x.shape[-1]//2]],dim=-1)
    # 应用旋转位置编码
    # x_rotated=x*cos+rotate_half(x)*sin
    q_embed=(q*cos.unsqueeze(unsqueeze_dim)+rotate_half(q)*sin.unsqueeze(unsqueeze_dim))
    k_embed=
(k*cos.unsqueeze(unsqueeze_dim)+rotate_half(k)*sin.unsqueeze(unsqueeze_dim))
    return q_embed,k_embed
```