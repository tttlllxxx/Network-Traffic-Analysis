## SiLU
$$SiLU(x)=\frac{x}{1+e^{-x}}$$
激活函数，引入非线性，逻辑的叠加嵌套
没有引入非线性的话：$y=w1(w2(w3\cdot x+b)+b)+b)$，多层等价于一层

## 代码
```Python
class FeedForward(nn.Module):
    # 初始化
    # 升维
    # 降维
    # 门控
    # dropout
    # 激活函数
    def __inf__(self,args:MiniMindConfig):
        super().__init__()
        if args.intermediate_size is None:
            intermediate_size=int(args.hidden_size*8/3)
            args.intermediate_size=64+((intermediate_size+64-1)//64)
            
        self.up_proj=nn.Linear(
            args.hidden_size,
            args.intermediate_size,
            bias=False
        )
        self.down_proj=nn.Linear(
            args.intermediate_size,
            args.hidden_size,
            bias=False
        )
        self.gate_proj=nn.Linear(
            args.hidden_size,
            args.intermediate_size,
            bias=False
        )
        self.dropout=nn.Dropout(args.dropout)
        self.act_fn=ACT2FN[args.hidden_act]
        
    def forward(self,x):
        return self.dropout(
            self.down_proj(self.act_fn(self.gate_proj(x)*self.up_proj(x)))
        )
```