基于注意力机制的简单网络架构：**Transformer**，省去了递归和卷积。

## 模型架构

![[The Transformer model architecture.png]]