提出一种 **双位置编码（Dual RoPE）机制**，将**时间信息与包顺序信息解耦并显式注入 Transformer 的注意力计算过程**，以增强模型对加密 LLM API 流量时序结构的建模能力。

具体而言：

- **统计特征** → 作为 token embedding，刻画“包的属性”
- **顺序 index RoPE** → 建模包在流中的阶段与协议结构
- **时间 RoPE（inter-arrival RoPE）** → 建模包之间的时间间隔与节奏模式

三者协同，使注意力机制同时感知 **结构顺序 + 时间动态**。

 **Token Embedding（Packet-level Statistical Features）**

每个网络包被表示为一个特征向量，包括但不限于：
- 包长度（如 log-scale）
- 方向（client → server / server → client）
- TCP 标志位（PSH / ACK / SYN 等）
- 是否为流式响应包

通过线性映射嵌入到 $\mathbb{R}^d$空间：

$\mathbf{e}_i = W_{\text{embed}} \mathbf{x}_i$


**顺序 Index RoPE（Packet Order Encoding）**

为每个包分配离散顺序索引：

$i \in \{0, 1, \dots, N-1\}$

顺序 RoPE 用于编码包在流中的**相对位置与阶段信息**，帮助模型区分：

- 握手阶段
- 请求阶段
- 响应/生成阶段

**时间 RoPE（Inter-arrival Time Encoding）**

定义相对时间位置：
$\Delta t_i = t_i - t_0$
或基于 inter-arrival time 的累积形式，并进行适当归一化或离散化。
时间 RoPE 被用于编码包之间的**时间间隔与节奏特征**，从而显式建模：

- request–response latency
- burst 模式
- 周期性 streaming 行为
- 异常高频或异常延迟调用

**双 RoPE 注入方式（Attention-level Integration）**
在注意力机制中，对 Query 和 Key 进行**连续的旋转位置编码**：

$\mathbf{q}_i' = R_{\text{order}}(i)\, R_{\text{time}}(\Delta t_i)\, \mathbf{q}_i$
$\mathbf{k}_i' = R_{\text{order}}(i)\, R_{\text{time}}(\Delta t_i)\, \mathbf{k}_i$

该设计使注意力权重同时受以下因素影响：

- 包顺序差（结构相似性）
- 时间差（节奏与延迟相似性）

从而在加密场景下引入强有力的时序归纳偏置。